{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "U58CQ-1e7d9Z",
        "HMgFJOlX7pSO",
        "qMcbDP_V7vTL",
        "Zku0hVjYwNOA",
        "Xe2ZRBG4_28g"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rinazbelhaj/EVA/blob/master/Project%202/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nJ7YEw_vyjG",
        "colab_type": "text"
      },
      "source": [
        "# **Not an ideal network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGWv5hBhv2jf",
        "colab_type": "code",
        "outputId": "5d0b4794-a4fa-400f-a05f-e721ad24ee95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "### This cell is installing keras using pip install\n",
        "\n",
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMlDJQKv4VG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3bfc0290-12d8-487f-a466-1892f80b9a09"
      },
      "source": [
        "### Here we are importing all the libraries needed for our modelling task\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Convolution2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CdSu2lMwB9s",
        "colab_type": "code",
        "outputId": "fca411c9-f11c-4a13-d2f4-987e6db20175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "### In this cell, we are loading MNIST hand written digits data to train and test numpy arrays\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLaDf0-rwCmj",
        "colab_type": "code",
        "outputId": "42d3ee67-708e-4239-a7e2-08d11e69b569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "# This cell displays the first value in training data\n",
        "\n",
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f582d0fbdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erb11jNwwFwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here we are reshapping the train and test images to be compatible with the model to be defined\n",
        "\n",
        "# The images are formatted to dimension Length*Width*Channel\n",
        "# Since MNIST is a collection of grey scale images, the channel will be 1. So dimension is 28*28*1\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLK4YDoRwHet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here we are changing the numpy value to float and normalizing them by dividing each value by 255\n",
        "# The pixel values are scaled between 0 and 1 which is benefecial for our network while backpropagating.\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKLOmhlwJQl",
        "colab_type": "code",
        "outputId": "f8be75bc-0ce7-4a13-841d-9232ef941ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# This cell display first 10 labels in our training data\n",
        "\n",
        "y_train[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YusMJguiwKsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "# This cell encodes one columns into 10 columns which basically has a flag corresponding to each class\n",
        "# Here 6th column is the flag for label 5 \n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxc99AswMW0",
        "colab_type": "code",
        "outputId": "aba9150b-dcf5-401d-f266-0cefe7d2b2b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Reformatted label data\n",
        "\n",
        "Y_train[:10]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irTVUE47wNwr",
        "colab_type": "code",
        "outputId": "3bef6175-b800-4a57-922a-5368777b83a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "source": [
        "# This cell defines our model\n",
        "\n",
        "# Importing building blocks for NN from keras.layers\n",
        "from keras.layers import Activation, MaxPooling2D\n",
        "\n",
        "# Defining model using Keras sequential API\n",
        "model = Sequential() \n",
        "\n",
        "# LRF = Local Receptive Field, GRF = Global Receptive Field\n",
        "\n",
        "# Layer 1 : Type=Convolution, Input=28*28*1, Kernel Size=3*3*1, No. of Kernels=32, Activation=RELU, LRF=3*3, GRF=3*3, Output=26*26*32\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "\n",
        "# Layer 2 : Type=Convolution, Input=26*26*32, Kernel Size=3*3*32, No. of Kernels=64, Activation=RELU, LRF=3*3, GRF=5*5, Output=24*24*64\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 3 : Type=Convolution, Input=24*24*64, Kernel Size=3*3*64, No. of Kernels=128, Activation=RELU, LRF=3*3, GRF=7*7, Output=22*22*128\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 4 : Type=Max Pooling, Input=22*22*128, Kernel Size=2*2, LRF=2*2, GRF=8*8, Output=11*11*128\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 5 : Type=Convolution, Input=11*11*128, Kernel Size=3*3*128, No. of Kernels=256, Activation=RELU, LRF=3*3, GRF=12*12, Output=9*9*256\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 6 : Type=Convolution, Input=9*9*256, Kernel Size=3*3*256, No. of Kernels=512, Activation=RELU, LRF=3*3, GRF=16*16, Output=7*7*512\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 7 : Type=Convolution, Input=7*7*512, Kernel Size=3*3*512, No. of Kernels=1024, Activation=RELU, LRF=3*3, GRF=20*20, Output=5*5*1024\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 8 : Type=Convolution, Input=5*5*1024, Kernel Size=3*3*1024, No. of Kernels=2048, Activation=RELU, LRF=3*3, GRF=24*24, Output=3*3*2048\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 9 : Type=Convolution, Input=3*3*2048, Kernel Size=3*3*2048, No. of Kernels=10, Activation=RELU, LRF=3*3, GRF=28*28, Output=1*1*10\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 10 : Flatten Layer : 1*1*10 to list of length 10\n",
        "model.add(Flatten())\n",
        "\n",
        "# Output : Softmax Function \n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Display model summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          184330    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,348,362\n",
            "Trainable params: 25,348,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZOpRb6yG7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the model\n",
        "\n",
        "# Loss function used is categorical cross entropy\n",
        "# Optimizer used is adam\n",
        "# Evaluation metric used is accuracy\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O248wVQyMft",
        "colab_type": "code",
        "outputId": "1ee7bd86-f9f2-4885-873e-67e733c959b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "# Training process\n",
        "# Fitting the model on training data\n",
        "\n",
        "# Batch Size: No of input images seen by the model at a given instance\n",
        "# Nb Epoch : Number of iterations over the training data\n",
        "# Verbose : The output display formatting of training process\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 219s 4ms/step - loss: 2.3027 - acc: 0.0987\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 214s 4ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 214s 4ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 214s 4ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 214s 4ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 214s 4ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 214s 4ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 214s 4ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 214s 4ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 214s 4ms/step - loss: 2.3026 - acc: 0.0987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc46e33bbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sst4KneiyOL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model evaluation on test data\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfJiXOKsyj4y",
        "colab_type": "code",
        "outputId": "1409d0fb-4b1d-4976-832b-b225449b3ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Model performance on the test data\n",
        "# Output score tells us the percentage of classes correctly predicted by our model\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.3025851249694824, 0.098]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwLSXt7nyn_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicting the label on test data\n",
        "\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKKoOKwyppN",
        "colab_type": "code",
        "outputId": "22c8607c-b5f8-4aa2-8023-140aeb774732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Comparing the prediction v/s actual for first 9 images in test data\n",
        "\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xcn5OOKVl2m",
        "colab_type": "text"
      },
      "source": [
        "### We can see that the model is not able to predict the label correctly. Infact, the model is giving same probabilty for all classes, which is same as the probability of random prediction 1/10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNayTrGVqC_r",
        "colab_type": "text"
      },
      "source": [
        "# What is wrong with the Network ?\n",
        "\n",
        "### The possible reason for the bad performance might be the combined effect of the following:\n",
        "\n",
        "\n",
        "### 1.   Pooling layer too close to input\n",
        "The max pooling layer is added as the 4th layer in the network after 3 convolution layers. The receptive field when max pooling is applied is just 7x7 which is not good enough to detect edges relevant for the correct classification. Hence max pooling layer is not getting enough information that it can use later to correctly classify the images. The pooling layer should have been little lower in the network to better identify important features than it can carry forward in the network.\n",
        "### 2.   No pooling layer after the first one to filter out irrelevant features\n",
        "Toward the lower half of the network, there are too many features generated by 5 layers of convolutions. Just before the final layer, there are 2048 channels suddenly converging into 10. All these happens without any pooling layer to select important channels for network. An extra pooling layer would have helped the network to learn better.\n",
        "\n",
        "### 3. Too many filters and parameters\n",
        "The network is too heavy for the given problem with far too many kernels used. The presence of too many kernels creates many irrelevent channels thereby introducing too much noise. The outputs of relevent channels gets ignored due to too many information coming in for the final layer. A much more simpler network should have been used considering the fact that input image is just 28x28.\n",
        "\n",
        "**Please find the below codes with the suggested changes that helped the model to learn**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U58CQ-1e7d9Z",
        "colab_type": "text"
      },
      "source": [
        "#1.  Model with max pooling few layers down in the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaBCc7S_bwaM",
        "colab_type": "code",
        "outputId": "20b64cf7-a531-45b7-d04d-42dcc5aae141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "source": [
        "# This cell defines our model\n",
        "\n",
        "# Importing building blocks for NN from keras.layers\n",
        "from keras.layers import Activation, MaxPooling2D\n",
        "\n",
        "# Defining model using Keras sequential API\n",
        "model = Sequential() \n",
        "\n",
        "# LRF = Local Receptive Field, GRF = Global Receptive Field\n",
        "\n",
        "# Layer 1 : Type=Convolution, Input=28*28*1, Kernel Size=3*3*1, No. of Kernels=32, Activation=RELU, LRF=3*3, GRF=3*3, Output=26*26*32\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "\n",
        "# Layer 2 : Type=Convolution, Input=26*26*32, Kernel Size=3*3*32, No. of Kernels=64, Activation=RELU, LRF=3*3, GRF=5*5, Output=24*24*64\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 3 : Type=Convolution, Input=24*24*64, Kernel Size=3*3*64, No. of Kernels=128, Activation=RELU, LRF=3*3, GRF=7*7, Output=22*22*128\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 4 : Type=Convolution, Input=22*22*128, Kernel Size=3*3*128, No. of Kernels=256, Activation=RELU, LRF=3*3, GRF=9*9, Output=20*20*256\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 5 : Type=Convolution, Input=20*20*256, Kernel Size=3*3*256, No. of Kernels=512, Activation=RELU, LRF=3*3, GRF=11*11, Output=18*18*512\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 6 : Type=Max Pooling, Input=18*18*512, Kernel Size=2*2, LRF=2*2, GRF=12*12, Output=9*9*512\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 7 : Type=Convolution, Input=9*9*512, Kernel Size=3*3*512, No. of Kernels=1024, Activation=RELU, LRF=3*3, GRF=16*16, Output=7*7*1024\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 8 : Type=Convolution, Input=7*7*1024, Kernel Size=3*3*512, No. of Kernels=1024, Activation=RELU, LRF=3*3, GRF=20*20, Output=5*5*1024\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 9 : Type=Convolution, Input=5*5*1024, Kernel Size=3*3*1024, No. of Kernels=2048, Activation=RELU, LRF=3*3, GRF=24*24, Output=3*3*2048\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 10 : Type=Convolution, Input=3*3*2048, Kernel Size=3*3*2048, No. of Kernels=10, Activation=RELU, LRF=3*3, GRF=28*28, Output=1*1*10\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 10 : Flatten Layer : 1*1*10 to list of length 10\n",
        "model.add(Flatten())\n",
        "\n",
        "# Output : Softmax Function \n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Display model summary\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 20, 20, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 7, 7, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 5, 5, 1024)        9438208   \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 1, 1, 10)          184330    \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 34,786,570\n",
            "Trainable params: 34,786,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhxDNH4leK0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "2fcf67a8-6295-43be-ce9b-dfee1d776cdc"
      },
      "source": [
        "# Compiling the model\n",
        "\n",
        "# Loss function used is categorical cross entropy\n",
        "# Optimizer used is adam\n",
        "# Evaluation metric used is accuracy\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# Training process\n",
        "# Fitting the model on training data\n",
        "\n",
        "# Batch Size: No of input images seen by the model at a given instance\n",
        "# Nb Epoch : Number of iterations over the training data\n",
        "# Verbose : The output display formatting of training process\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=512, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 83s 1ms/step - loss: 1.2394 - acc: 0.5218\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 70s 1ms/step - loss: 0.9605 - acc: 0.5956\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 69s 1ms/step - loss: 0.9451 - acc: 0.5982\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 69s 1ms/step - loss: 0.9372 - acc: 0.5998\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 69s 1ms/step - loss: 0.9330 - acc: 0.6002\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 69s 1ms/step - loss: 0.9300 - acc: 0.6006\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 69s 1ms/step - loss: 0.8621 - acc: 0.6335\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 69s 1ms/step - loss: 0.6907 - acc: 0.7052\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 69s 1ms/step - loss: 0.6858 - acc: 0.7056\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 69s 1ms/step - loss: 0.6852 - acc: 0.7057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c25533d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMgFJOlX7pSO",
        "colab_type": "text"
      },
      "source": [
        "# 2. Model with two max pooling layers in the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QazWWGyeQ4_",
        "colab_type": "code",
        "outputId": "32a01570-fcbc-4f37-d1e2-a9bed52e3b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "source": [
        "# This cell defines our model\n",
        "\n",
        "# Importing building blocks for NN from keras.layers\n",
        "from keras.layers import Activation, MaxPooling2D\n",
        "\n",
        "# Defining model using Keras sequential API\n",
        "model = Sequential() \n",
        "\n",
        "# LRF = Local Receptive Field, GRF = Global Receptive Field\n",
        "\n",
        "# Layer 1 : Type=Convolution, Input=28*28*1, Kernel Size=3*3*1, No. of Kernels=32, Activation=RELU, LRF=3*3, GRF=3*3, Output=26*26*32\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "\n",
        "# Layer 2 : Type=Convolution, Input=26*26*32, Kernel Size=3*3*32, No. of Kernels=64, Activation=RELU, LRF=3*3, GRF=5*5, Output=24*24*64\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 3 : Type=Convolution, Input=24*24*64, Kernel Size=3*3*64, No. of Kernels=128, Activation=RELU, LRF=3*3, GRF=7*7, Output=22*22*128\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 4 : Type=Max Pooling, Input=22*22*128, Kernel Size=2*2, LRF=2*2, GRF=8*8, Output=11*11*128\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 5 : Type=Convolution, Input=11*11*128, Kernel Size=3*3*128, No. of Kernels=256, Activation=RELU, LRF=3*3, GRF=12*12, Output=9*9*256\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 6 : Type=Convolution, Input=9*9*256, Kernel Size=3*3*256, No. of Kernels=512, Activation=RELU, LRF=3*3, GRF=16*16, Output=7*7*512\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 7 : Type=Max Pooling, Input=7*7*512, Kernel Size=2*2, LRF=2*2, GRF=18*18, Output=3*3*512\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 9 : Type=Convolution, Input=3*3*512, Kernel Size=3*3*512, No. of Kernels=10, Activation=RELU, LRF=3*3, GRF=26*26, Output=1*1*10\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 10 : Flatten Layer : 1*1*10 to list of length 10\n",
        "model.add(Flatten())\n",
        "\n",
        "# Output : Softmax Function \n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Display model summary\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 1, 1, 10)          46090     \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,614,090\n",
            "Trainable params: 1,614,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35tPe5mqeUL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "3f4b3f17-863d-45e7-e800-928ddcdc3467"
      },
      "source": [
        "# Compiling the model\n",
        "\n",
        "# Loss function used is categorical cross entropy\n",
        "# Optimizer used is adam\n",
        "# Evaluation metric used is accuracy\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# Training process\n",
        "# Fitting the model on training data\n",
        "\n",
        "# Batch Size: No of input images seen by the model at a given instance\n",
        "# Nb Epoch : Number of iterations over the training data\n",
        "# Verbose : The output display formatting of training process\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=2048, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 20s 338us/step - loss: 1.6080 - acc: 0.4553\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 1.2649 - acc: 0.5690\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 1.2245 - acc: 0.5774\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 1.2105 - acc: 0.5802\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 1.2013 - acc: 0.5821\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 1.1978 - acc: 0.5830\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 1.1936 - acc: 0.5839\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 1.1940 - acc: 0.5836\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 1.1893 - acc: 0.5850\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 1.1861 - acc: 0.5855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c24c56828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMcbDP_V7vTL",
        "colab_type": "text"
      },
      "source": [
        "# 3. Model with two max pooling layers and lesser parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NMKrMjAiQNt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "4d0228a6-01a3-420d-c5d0-566052aa8071"
      },
      "source": [
        "# This cell defines our model\n",
        "\n",
        "# Importing building blocks for NN from keras.layers\n",
        "from keras.layers import Activation, MaxPooling2D\n",
        "\n",
        "# Defining model using Keras sequential API\n",
        "model = Sequential() \n",
        "\n",
        "# LRF = Local Receptive Field, GRF = Global Receptive Field\n",
        "\n",
        "# Layer 1 : Type=Convolution, Input=28*28*1, Kernel Size=3*3*1, No. of Kernels=8, Activation=RELU, LRF=3*3, GRF=3*3, Output=26*26*8\n",
        "model.add(Convolution2D(8, (3, 3), activation='relu', input_shape=(28,28,1),name='conv_1'))\n",
        "\n",
        "# Layer 2 : Type=Max Pooling, Input=26*26*8, Kernel Size=2*2, LRF=2*2, GRF=4*4, Output=13*13*8\n",
        "model.add(MaxPooling2D((2, 2),name='pool_1'))\n",
        "\n",
        "# Layer 3 : Type=Convolution, Input=13*13*8, Kernel Size=3*3*8, No. of Kernels=32, Activation=RELU, LRF=3*3, GRF=8*8, Output=11*11*32\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu',name='conv_2'))\n",
        "\n",
        "# Layer 4 : Type=Max Pooling, Input=11*11*32, Kernel Size=2*2, LRF=2*2, GRF=10*10, Output=5*5*32\n",
        "model.add(MaxPooling2D((2, 2),name='pool_2'))\n",
        "\n",
        "# Layer 5 : Type=Convolution, Input=5*5*32, Kernel Size=3*3*32, No. of Kernels=40, Activation=RELU, LRF=3*3, GRF=18*18, Output=3*3*40\n",
        "model.add(Convolution2D(40, (3, 3), activation='relu',name='conv_3'))\n",
        "\n",
        "# Layer 6 : Type=Convolution, Input=3*3*40, Kernel Size=3*3*40, No. of Kernels=10, Activation=RELU, LRF=3*3, GRF=26*26, Output=1*1*10\n",
        "model.add(Convolution2D(10, (3, 3), activation='relu',name='conv_4'))\n",
        "\n",
        "# Layer 7 : Flatten Layer : 1*1*10 to list of length 10\n",
        "model.add(Flatten(name='flatten'))\n",
        "\n",
        "# Output : Softmax Function\n",
        "model.add(Activation('softmax',name='activation'))\n",
        "\n",
        "# Display model summary\n",
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_1 (Conv2D)              (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "pool_1 (MaxPooling2D)        (None, 13, 13, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 11, 11, 32)        2336      \n",
            "_________________________________________________________________\n",
            "pool_2 (MaxPooling2D)        (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 3, 3, 40)          11560     \n",
            "_________________________________________________________________\n",
            "conv_4 (Conv2D)              (None, 1, 1, 10)          3610      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 17,586\n",
            "Trainable params: 17,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuM4QL-d7Ge0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "737a60d4-8e44-4c48-9685-f3e9d249d3f9"
      },
      "source": [
        "# Compiling the model\n",
        "\n",
        "# Loss function used is categorical cross entropy\n",
        "# Optimizer used is adam\n",
        "# Evaluation metric used is accuracy\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# Training process\n",
        "# Fitting the model on training data\n",
        "\n",
        "# Batch Size: No of input images seen by the model at a given instance\n",
        "# Nb Epoch : Number of iterations over the training data\n",
        "# Verbose : The output display formatting of training process\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=2048, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 1.9462 - acc: 0.4464\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 1.0591 - acc: 0.6843\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.8088 - acc: 0.7251\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.7260 - acc: 0.7431\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.6761 - acc: 0.7542\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.6390 - acc: 0.7615\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.6129 - acc: 0.7671\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.5945 - acc: 0.7708\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.5823 - acc: 0.7727\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.5723 - acc: 0.7748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c24c47dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zku0hVjYwNOA",
        "colab_type": "text"
      },
      "source": [
        "# 4. Model with activation removed from last conv layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9f8BUF17KpQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "de5b1408-a8f0-4f4b-f55b-2f5d5a34938b"
      },
      "source": [
        "# This cell defines our model\n",
        "\n",
        "# Importing building blocks for NN from keras.layers\n",
        "from keras.layers import Activation, MaxPooling2D\n",
        "\n",
        "# Defining model using Keras sequential API\n",
        "model = Sequential() \n",
        "\n",
        "# LRF = Local Receptive Field, GRF = Global Receptive Field\n",
        "\n",
        "# Layer 1 : Type=Convolution, Input=28*28*1, Kernel Size=3*3*1, No. of Kernels=32, Activation=RELU, LRF=3*3, GRF=3*3, Output=26*26*32\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "\n",
        "# Layer 2 : Type=Convolution, Input=26*26*32, Kernel Size=3*3*32, No. of Kernels=64, Activation=RELU, LRF=3*3, GRF=5*5, Output=24*24*64\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 3 : Type=Convolution, Input=24*24*64, Kernel Size=3*3*64, No. of Kernels=128, Activation=RELU, LRF=3*3, GRF=7*7, Output=22*22*128\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 4 : Type=Max Pooling, Input=22*22*128, Kernel Size=2*2, LRF=2*2, GRF=8*8, Output=11*11*128\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Layer 5 : Type=Convolution, Input=11*11*128, Kernel Size=3*3*128, No. of Kernels=256, Activation=RELU, LRF=3*3, GRF=12*12, Output=9*9*256\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 6 : Type=Convolution, Input=9*9*256, Kernel Size=3*3*256, No. of Kernels=512, Activation=RELU, LRF=3*3, GRF=16*16, Output=7*7*512\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 7 : Type=Convolution, Input=7*7*512, Kernel Size=3*3*512, No. of Kernels=1024, Activation=RELU, LRF=3*3, GRF=20*20, Output=5*5*1024\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 8 : Type=Convolution, Input=5*5*1024, Kernel Size=3*3*1024, No. of Kernels=2048, Activation=RELU, LRF=3*3, GRF=24*24, Output=3*3*2048\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu'))\n",
        "\n",
        "# Layer 9 : Type=Convolution, Input=3*3*2048, Kernel Size=3*3*2048, No. of Kernels=10, Activation=RELU, LRF=3*3, GRF=28*28, Output=1*1*10\n",
        "model.add(Convolution2D(10, 3, 3))\n",
        "\n",
        "# Layer 10 : Flatten Layer : 1*1*10 to list of length 10\n",
        "model.add(Flatten())\n",
        "\n",
        "# Output : Softmax Function \n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Display model summary\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          184330    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,348,362\n",
            "Trainable params: 25,348,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZCSJ4A-ven8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "0f804ed8-6fa2-4523-e16b-49263664a903"
      },
      "source": [
        "# Compiling the model\n",
        "\n",
        "# Loss function used is categorical cross entropy\n",
        "# Optimizer used is adam\n",
        "# Evaluation metric used is accuracy\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# Training process\n",
        "# Fitting the model on training data\n",
        "\n",
        "# Batch Size: No of input images seen by the model at a given instance\n",
        "# Nb Epoch : Number of iterations over the training data\n",
        "# Verbose : The output display formatting of training process\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 119s 2ms/step - loss: 0.1518 - acc: 0.9530\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0539 - acc: 0.9842\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0418 - acc: 0.9880\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0345 - acc: 0.9904\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0275 - acc: 0.9924\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0252 - acc: 0.9929\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0233 - acc: 0.9938\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0229 - acc: 0.9936\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0202 - acc: 0.9945\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0194 - acc: 0.9953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f582d0cee10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHSTDxaU5jgE",
        "colab_type": "text"
      },
      "source": [
        "## Actual Reason\n",
        "\n",
        "The last convoultion with relu activation function was removing negative values hence the model was loosing its discriminating power. Because of this, the accuracy was not improving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe2ZRBG4_28g",
        "colab_type": "text"
      },
      "source": [
        "# Plotting Final Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn26B6og6Mh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting functions\n",
        "\n",
        "## make_mosaic(im, nrows, ncols, border=1)\n",
        "## Create a numpy mosaic from a list of matrix.\n",
        "\n",
        "## get_weights_mosaic(model, layer_id, n=64)\n",
        "## Get the weights of the layer of a model as a numpy mosaic.\n",
        "\n",
        "## plot_weights(model, layer_id, n=64, ax=None, **kwargs)\n",
        "## Plot the weights of a specific layer with matplotlib\n",
        "\n",
        "## plot_all_weights(model, n=64, **kwargs)\n",
        "## Plot all the possible 2D weights in the model\n",
        "\n",
        "## plot_feature_map(model, layer_id, X, n=256, ax=None, **kwargs)\n",
        "## Plot the feature maps of the layer of a model\n",
        "\n",
        "## plot_all_feature_maps(model, X, n=256, ax=None, **kwargs)\n",
        "## Plot all the feature maps of every possible layers\n",
        "\n",
        "def make_mosaic(im, nrows, ncols, border=1):\n",
        "    \"\"\"From http://nbviewer.jupyter.org/github/julienr/ipynb_playground/blob/master/keras/convmnist/keras_cnn_mnist.ipynb\n",
        "    \"\"\"\n",
        "    import numpy.ma as ma\n",
        "\n",
        "    nimgs = len(im)\n",
        "    imshape = im[0].shape\n",
        "    \n",
        "    mosaic = ma.masked_all((nrows * imshape[0] + (nrows - 1) * border,\n",
        "                            ncols * imshape[1] + (ncols - 1) * border),\n",
        "                            dtype=np.float32)\n",
        "    \n",
        "    paddedh = imshape[0] + border\n",
        "    paddedw = imshape[1] + border\n",
        "    im\n",
        "    for i in range(nimgs):\n",
        "        \n",
        "        row = int(np.floor(i / ncols))\n",
        "        col = i % ncols\n",
        "        \n",
        "        mosaic[row * paddedh:row * paddedh + imshape[0],\n",
        "               col * paddedw:col * paddedw + imshape[1]] = im[i]\n",
        "        \n",
        "    return mosaic\n",
        "\n",
        "\n",
        "def get_weights_mosaic(model, layer_id, n=64):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    \n",
        "    # Get Keras layer\n",
        "    layer = model.layers[layer_id]\n",
        "\n",
        "    # Check if this layer has weight values\n",
        "    if not hasattr(layer, \"W\"):\n",
        "        raise Exception(\"The layer {} of type {} does not have weights.\".format(layer.name,\n",
        "                                                           layer.__class__.__name__))\n",
        "        \n",
        "    weights = layer.W.get_value()\n",
        "    \n",
        "    # For now we only handle Conv layer like with 4 dimensions\n",
        "    if weights.ndim != 4:\n",
        "        raise Exception(\"The layer {} has {} dimensions which is not supported.\".format(layer.name, weights.ndim))\n",
        "    \n",
        "    # n define the maximum number of weights to display\n",
        "    if weights.shape[0] < n:\n",
        "        n = weights.shape[0]\n",
        "        \n",
        "    # Create the mosaic of weights\n",
        "    nrows = int(np.round(np.sqrt(n)))\n",
        "    ncols = int(nrows)\n",
        "\n",
        "    if nrows ** 2 < n:\n",
        "        ncols +=1\n",
        "\n",
        "    mosaic = make_mosaic(weights[:n, 0], nrows, ncols, border=1)\n",
        "    \n",
        "    return mosaic\n",
        "\n",
        "\n",
        "def plot_weights(model, layer_id, n=64, ax=None, **kwargs):\n",
        "    \"\"\"Plot the weights of a specific layer. ndim must be 4.\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    # Set default matplotlib parameters\n",
        "    if not 'interpolation' in kwargs.keys():\n",
        "        kwargs['interpolation'] = \"none\"\n",
        "        \n",
        "    if not 'cmap' in kwargs.keys():\n",
        "        kwargs['cmap'] = \"gray\"\n",
        "    \n",
        "    layer = model.layers[layer_id]\n",
        "    \n",
        "    mosaic = get_weights_mosaic(model, layer_id, n=64)\n",
        "    \n",
        "    # Plot the mosaic\n",
        "    if not ax:\n",
        "        fig = plt.figure()\n",
        "        ax = plt.subplot()\n",
        "    \n",
        "    im = ax.imshow(mosaic, **kwargs)\n",
        "    ax.set_title(\"Layer #{} called '{}' of type {}\".format(layer_id, layer.name, layer.__class__.__name__))\n",
        "    \n",
        "    plt.colorbar(im, ax=ax)\n",
        "    \n",
        "    return ax\n",
        "\n",
        "\n",
        "def plot_all_weights(model, n=64, **kwargs):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "    \n",
        "    # Set default matplotlib parameters\n",
        "    if not 'interpolation' in kwargs.keys():\n",
        "        kwargs['interpolation'] = \"none\"\n",
        "\n",
        "    if not 'cmap' in kwargs.keys():\n",
        "        kwargs['cmap'] = \"gray\"\n",
        "\n",
        "    layers_to_show = []\n",
        "\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        if hasattr(layer, \"W\"):\n",
        "            weights = layer.W.get_value()\n",
        "            if weights.ndim == 4:\n",
        "                layers_to_show.append((i, layer))\n",
        "\n",
        "\n",
        "    fig = plt.figure(figsize=(15, 15))\n",
        "    \n",
        "    n_mosaic = len(layers_to_show)\n",
        "    nrows = int(np.round(np.sqrt(n_mosaic)))\n",
        "    ncols = int(nrows)\n",
        "\n",
        "    if nrows ** 2 < n_mosaic:\n",
        "        ncols +=1\n",
        "\n",
        "    for i, (layer_id, layer) in enumerate(layers_to_show):\n",
        "\n",
        "        mosaic = get_weights_mosaic(model, layer_id=layer_id, n=n)\n",
        "\n",
        "        ax = fig.add_subplot(nrows, ncols, i+1)\n",
        "        \n",
        "        im = ax.imshow(mosaic, **kwargs)\n",
        "        ax.set_title(\"Layer #{} called '{}' of type {}\".format(layer_id, layer.name, layer.__class__.__name__))\n",
        "\n",
        "        divider = make_axes_locatable(ax)\n",
        "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
        "        plt.colorbar(im, cax=cax)\n",
        "        \n",
        "    fig.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "def plot_feature_map(model, layer_id, X, n=256, ax=None, **kwargs):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    import keras.backend as K\n",
        "    import matplotlib.pyplot as plt\n",
        "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "    layer = model.layers[layer_id]\n",
        "    \n",
        "    try:\n",
        "        get_activations = K.function([model.layers[0].input, K.learning_phase()], [layer.output,])\n",
        "        activations = get_activations([X, 0])[0]\n",
        "    except:\n",
        "        # Ugly catch, a cleaner logic is welcome here.\n",
        "        raise Exception(\"This layer cannot be plotted.\")\n",
        "        \n",
        "    # For now we only handle feature map with 4 dimensions\n",
        "    if activations.ndim != 4:\n",
        "        raise Exception(\"Feature map of '{}' has {} dimensions which is not supported.\".format(layer.name,\n",
        "                                                                                             activations.ndim))\n",
        "        \n",
        "    # Set default matplotlib parameters\n",
        "    if not 'interpolation' in kwargs.keys():\n",
        "        kwargs['interpolation'] = \"none\"\n",
        "\n",
        "    if not 'cmap' in kwargs.keys():\n",
        "        kwargs['cmap'] = \"gray\"\n",
        "        \n",
        "    fig = plt.figure(figsize=(15, 15))\n",
        "    \n",
        "    # Compute nrows and ncols for images\n",
        "    n_mosaic = len(activations)\n",
        "    nrows = int(np.round(np.sqrt(n_mosaic)))\n",
        "    ncols = int(nrows)\n",
        "    if (nrows ** 2) < n_mosaic:\n",
        "        ncols +=1\n",
        "        \n",
        "    # Compute nrows and ncols for mosaics\n",
        "    if activations[0].shape[0] < n:\n",
        "        n = activations[0].shape[0]\n",
        "        \n",
        "    nrows_inside_mosaic = int(np.round(np.sqrt(n)))\n",
        "    ncols_inside_mosaic = int(nrows_inside_mosaic)\n",
        "\n",
        "    if nrows_inside_mosaic ** 2 < n:\n",
        "        ncols_inside_mosaic += 1\n",
        "\n",
        "    for i, feature_map in enumerate(activations):\n",
        "\n",
        "        mosaic = make_mosaic(feature_map[:n], nrows_inside_mosaic, ncols_inside_mosaic, border=1)\n",
        "\n",
        "        ax = fig.add_subplot(nrows, ncols, i+1)\n",
        "        \n",
        "        im = ax.imshow(mosaic, **kwargs)\n",
        "        ax.set_title(\"Feature map #{} \\nof layer#{} \\ncalled '{}' \\nof type {} \".format(i, layer_id,\n",
        "                                                                                  layer.name,\n",
        "                                                                                  layer.__class__.__name__))\n",
        "\n",
        "        divider = make_axes_locatable(ax)\n",
        "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
        "        plt.colorbar(im, cax=cax)\n",
        "            \n",
        "    fig.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "def plot_all_feature_maps(model, X, n=256, ax=None, **kwargs):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    \n",
        "    figs = []\n",
        "    \n",
        "    for i, layer in enumerate(model.layers):\n",
        "        \n",
        "        try:\n",
        "            fig = plot_feature_map(model, i, X, n=n, ax=ax, **kwargs)\n",
        "        except:\n",
        "            pass\n",
        "        else:\n",
        "            figs.append(fig)\n",
        "            \n",
        "    return figs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKXcUecU70Pr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "outputId": "9be22afa-cbea-4b7c-c014-6fee43de7dbd"
      },
      "source": [
        "# Plot all the feature maps of the layer 2\n",
        "# The maximum number of filters per feature maps is n=9\n",
        "\n",
        "_ = plot_feature_map(model, 8, X_test[:12], n=9)\n",
        "#_ = plot_all_feature_maps(model, X_test[:9], n=9)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAALWCAYAAACwWWOzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x1080 with 24 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}